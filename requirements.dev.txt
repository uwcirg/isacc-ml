#
# This file is autogenerated by pip-compile with Python 3.9
# by the following command:
#
#    pip-compile --extra=dev --output-file=requirements.dev.txt setup.cfg
#
attrs==24.2.0
    # via
    #   cattrs
    #   requests-cache
blinker==1.8.2
    # via flask
cattrs==23.2.3
    # via requests-cache
certifi==2024.7.4
    # via requests
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via flask
exceptiongroup==1.2.2
    # via
    #   cattrs
    #   pytest
filelock==3.15.4
    # via
    #   huggingface-hub
    #   torch
    #   transformers
    #   triton
flask==3.0.3
    # via ml_services (setup.cfg)
fsspec==2024.6.1
    # via
    #   huggingface-hub
    #   torch
gunicorn==23.0.0
    # via ml_services (setup.cfg)
huggingface-hub==0.24.6
    # via
    #   tokenizers
    #   transformers
idna==3.7
    # via requests
importlib-metadata==8.4.0
    # via flask
iniconfig==2.0.0
    # via pytest
itsdangerous==2.2.0
    # via flask
jinja2==3.1.4
    # via
    #   flask
    #   torch
markupsafe==2.1.5
    # via
    #   jinja2
    #   werkzeug
mpmath==1.3.0
    # via sympy
networkx==3.2.1
    # via torch
numpy==2.0.1
    # via
    #   ml_services (setup.cfg)
    #   pandas
    #   scipy
    #   transformers
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.6.20
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
packaging==24.1
    # via
    #   gunicorn
    #   huggingface-hub
    #   pytest
    #   transformers
pandas==2.2.2
    # via ml_services (setup.cfg)
platformdirs==4.2.2
    # via requests-cache
pluggy==1.5.0
    # via pytest
pytest==8.3.2
    # via
    #   ml_services (setup.cfg)
    #   pytest-datadir
    #   pytest-mock
pytest-datadir==1.5.0
    # via ml_services (setup.cfg)
pytest-mock==3.14.0
    # via ml_services (setup.cfg)
python-dateutil==2.9.0.post0
    # via pandas
pytz==2024.1
    # via pandas
pyyaml==6.0.2
    # via
    #   huggingface-hub
    #   transformers
equests==2.32.3
    # via
    #   huggingface-hub
    #   requests-cache
    #   requests-mock
    #   transformers
requests-cache==1.2.1
    # via ml_services (setup.cfg)
requests-mock==1.12.1
    # via ml_services (setup.cfg)
scipy==1.13.1
    # via ml_services (setup.cfg)
six==1.16.0
    # via
    #   python-dateutil
    #   url-normalize
sympy==1.13.2
    # via torch
tomli==2.0.1
    # via pytest
torch==2.4.0
    # via ml_services (setup.cfg)
tqdm==4.66.5
    # via
    #   huggingface-hub
    #   transformers
# Pinned because of compatability issues, https://github.com/huggingface/transformers/issues/30965
transformers==4.37.0
    # via ml_services (setup.cfg)
triton==3.0.0
    # via torch
typing-extensions==4.12.2
    # via
    #   cattrs
    #   huggingface-hub
    #   torch
tzdata==2024.1
    # via pandas
url-normalize==1.4.3
    # via requests-cache
urllib3==2.2.2
    # via
    #   requests
    #   requests-cache
werkzeug==3.0.3
    # via flask
zipp==3.20.0
    # via importlib-metadata
